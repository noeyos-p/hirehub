from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
import os
from dotenv import load_dotenv
import openai # âœ… êµ¬ë²„ì „ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ì†Œë¬¸ì import
import time # âœ… ì§€ìˆ˜ ë°±ì˜¤í”„ë¥¼ ìœ„í•œ time ëª¨ë“ˆ ì¶”ê°€

# âœ… .env íŒŒì¼ ë¡œë“œ (main.pyì™€ ê°™ì€ í´ë”ì— ìˆì–´ì•¼ í•¨)
load_dotenv()

# âœ… API í‚¤ ë¡œë“œ
api_key = os.getenv("OPENAI_API_KEY", "")

# âœ… OpenAI API í‚¤ ì„¤ì • (êµ¬ë²„ì „ ë°©ì‹)
# êµ¬ë²„ì „ì€ ëª¨ë“ˆì— api_keyë¥¼ ì§ì ‘ ì„¤ì •í•©ë‹ˆë‹¤.
openai.api_key = api_key

# âœ… API í‚¤ í™•ì¸ ë° ì¶œë ¥ (ë””ë²„ê¹…ìš©)
print(f"ğŸ”‘ API í‚¤ ë¡œë“œ ì—¬ë¶€: {'ìˆìŒ' if openai.api_key else 'ì—†ìŒ'}")
if openai.api_key:
    print(f"ğŸ”‘ API í‚¤ ì• 7ì: {openai.api_key[:7]}...")


app = FastAPI()

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:5173", "https://noeyos.store"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class ChatRequest(BaseModel):
    message: str


@app.get("/")
async def root():
    return {"status": "AI Server is running (v0.28.1 Syntax)", "version": "1.0.0"}


def call_openai_with_retry(messages, model, max_tokens, temperature, max_retries=3):
    """ì§€ìˆ˜ ë°±ì˜¤í”„ë¥¼ ì‚¬ìš©í•˜ì—¬ OpenAI APIë¥¼ í˜¸ì¶œí•˜ëŠ” í•¨ìˆ˜ (v0.28.1 êµ¬ë¬¸)"""
    base_delay = 1 # ì´ˆê¸° ì§€ì—° ì‹œê°„ (ì´ˆ)

    for attempt in range(max_retries):
        try:
            # âœ… êµ¬ë²„ì „ OpenAI API í˜¸ì¶œ êµ¬ë¬¸
            completion = openai.ChatCompletion.create(
                model=model,
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature
            )
            return completion

        except openai.error.APIError as e:
            # API ê´€ë ¨ ì˜¤ë¥˜ ì²˜ë¦¬ (4xx, 5xx)
            if attempt < max_retries - 1:
                delay = base_delay * (2 ** attempt)
                print(f"âš ï¸ API ì˜¤ë¥˜ ë°œìƒ (ì‹œë„ {attempt + 1}/{max_retries}): {e}. {delay:.1f}ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤.")
                time.sleep(delay)
            else:
                raise e # ë§ˆì§€ë§‰ ì‹œë„ ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒ
        
        except openai.error.RateLimitError as e:
            # ì†ë„ ì œí•œ ì˜¤ë¥˜ ì²˜ë¦¬
            if attempt < max_retries - 1:
                delay = base_delay * (2 ** attempt)
                print(f"âš ï¸ ì†ë„ ì œí•œ ì˜¤ë¥˜ ë°œìƒ (ì‹œë„ {attempt + 1}/{max_retries}): {e}. {delay:.1f}ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤.")
                time.sleep(delay)
            else:
                raise e # ë§ˆì§€ë§‰ ì‹œë„ ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒ
        
        except Exception as e:
            # ê¸°íƒ€ ì˜ˆì™¸ (ConnectionError ë“±)
            raise e


@app.post("/ai/chat")
async def chat(req: ChatRequest):
    try:
        print(f"ğŸ“¨ ë°›ì€ ë©”ì‹œì§€: {req.message}")

        # âœ… API í‚¤ í™•ì¸ (êµ¬ë²„ì „ ëª¨ë“ˆ ë³€ìˆ˜ ì‚¬ìš©)
        if not openai.api_key:
            print("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
            return {"answer": "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."}

        # API í˜¸ì¶œì— ì‚¬ìš©í•  ë©”ì‹œì§€ êµ¬ì„±
        messages = [
            {
                "role": "system",
                "content": "ë‹¹ì‹ ì€ ì±„ìš© í”Œë«í¼ HireHubì˜ ì¹œì ˆí•œ ê³ ê° ì§€ì› AI ì±—ë´‡ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëª…í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”."
            },
            {
                "role": "user",
                "content": req.message
            }
        ]

        # âœ… ì§€ìˆ˜ ë°±ì˜¤í”„ë¥¼ ì‚¬ìš©í•˜ëŠ” API í˜¸ì¶œ í•¨ìˆ˜ ì‚¬ìš©
        completion = call_openai_with_retry(
            messages=messages,
            model="gpt-4o-mini", # ì´ ëª¨ë¸ì€ v0.28.1 ì‹œì ì—ëŠ” ì¡´ì¬í•˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ, ì‹¤ì œ êµ¬ë™ ì‹œ ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (gpt-3.5-turbo ê¶Œì¥)
            max_tokens=500,
            temperature=0.7
        )

        # ì‘ë‹µ ì¶”ì¶œ (êµ¬ë²„ì „ê³¼ ìµœì‹  ë²„ì „ ëª¨ë‘ ìœ ì‚¬í•œ êµ¬ì¡°ë¥¼ ê°€ì§)
        answer = completion.choices[0].message.content
        print(f"âœ… AI ì‘ë‹µ: {answer}")
        return {"answer": answer}

    except openai.error.AuthenticationError as e:
        print(f"âŒ ì¸ì¦ ì˜¤ë¥˜: {e}")
        return {
            "answer": "OpenAI ì¸ì¦ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
        }
    except Exception as e:
        error_type = type(e).__name__
        print(f"âŒ Error: {error_type}")
        print(f"âŒ Error ìƒì„¸: {e}")
        return {
            "answer": f"AI ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤ ({error_type}): {str(e)}"
        }


@app.get("/health")
async def health_check():
    return {"status": "healthy"}


if __name__ == "__main__":
    # FastAPIëŠ” "main" ëª¨ë“ˆì—ì„œ "app" ê°ì²´ë¥¼ ì°¾ì•„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    # --reload ì˜µì…˜ì€ ê°œë°œ í™˜ê²½ì—ì„œ ì½”ë“œ ë³€ê²½ ì‹œ ìë™ ì¬ì‹œì‘ì„ ì§€ì›í•©ë‹ˆë‹¤.
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)