from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
import os
import json              # ğŸ‘ˆ ì—¬ê¸° ì¶”ê°€
from dotenv import load_dotenv  # âœ… ì¶”ê°€
from openai import OpenAI
from typing import Optional, List, Dict, Any

# âœ… .env íŒŒì¼ ë¡œë“œ (main.pyì™€ ê°™ì€ í´ë”ì— ìˆì–´ì•¼ í•¨)
load_dotenv()

# âœ… API í‚¤ í™•ì¸ ë° ì¶œë ¥ (ë””ë²„ê¹…ìš©)
api_key = os.getenv("OPENAI_API_KEY", "")
print(f"ğŸ”‘ API í‚¤ ë¡œë“œ ì—¬ë¶€: {'ìˆìŒ' if api_key else 'ì—†ìŒ'}")
if api_key:
    print(f"ğŸ”‘ API í‚¤ ì• 7ì: {api_key[:7]}...")

# âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=api_key)

app = FastAPI()

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://localhost:5173", "https://noeyos.store"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class ChatRequest(BaseModel):
    message: str


@app.get("/")
async def root():
    return {"status": "AI Server is running", "version": "1.0.0"}

#  ai ì±—ë´‡ ìƒë‹´ê¸°ëŠ¥
@app.post("/ai/chat")
async def chat(req: ChatRequest):
    try:
        print(f"ğŸ“¨ ë°›ì€ ë©”ì‹œì§€: {req.message}")

        # âœ… API í‚¤ í™•ì¸
        if not client.api_key:
            print("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
            return {"answer": "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."}

        # âœ… OpenAI API í˜¸ì¶œ
        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "ë‹¹ì‹ ì€ ì±„ìš© í”Œë«í¼ HireHubì˜ ì¹œì ˆí•œ ê³ ê° ì§€ì› AI ì±—ë´‡ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëª…í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”."
                },
                {
                    "role": "users",
                    "content": req.message
                }
            ],
            max_tokens=500,
            temperature=0.7
        )

        answer = completion.choices[0].message.content
        print(f"âœ… AI ì‘ë‹µ: {answer}")
        return {"answer": answer}

    except Exception as e:
        print(f"âŒ Error: {type(e).__name__}")
        print(f"âŒ Error ìƒì„¸: {e}")
        return {
            "answer": f"AI ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        }


@app.get("/health")
async def health_check():
    return {"status": "healthy"}

# ìê¸°ì†Œê°œì„œ ai ì²¨ì‚­ê¸°ëŠ¥

class ResumeReviewRequest(BaseModel):
    title: Optional[str] = None
    essayTitle: Optional[str] = None
    essayContent: str

    profile: Optional[Dict[str, Any]] = None
    educations: Optional[List[Dict[str, Any]]] = None
    careers: Optional[List[Dict[str, Any]]] = None
    certs: Optional[List[str]] = None
    skills: Optional[List[str]] = None
    langs: Optional[List[str]] = None

@app.post("/ai/review")
async def review_resume(req: ResumeReviewRequest):
    try:
        # JSON ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ì •ë¦¬
        profile_info = json.dumps(req.profile or {}, ensure_ascii=False, indent=2)
        educations = json.dumps(req.educations or [], ensure_ascii=False, indent=2)
        careers = json.dumps(req.careers or [], ensure_ascii=False, indent=2)
        certs = json.dumps(req.certs or [], ensure_ascii=False, indent=2)
        skills = json.dumps(req.skills or [], ensure_ascii=False, indent=2)
        langs = json.dumps(req.langs or [], ensure_ascii=False, indent=2)

        prompt = f"""
ë‹¹ì‹ ì€ ì „ë¬¸ ì±„ìš©ë‹´ë‹¹ìì…ë‹ˆë‹¤.
ì•„ë˜ ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì´ë ¥ì„œ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬,
ìê¸°ì†Œê°œì„œë¥¼ **ìƒí™©ì— ë§ê²Œ ì •í™•í•˜ê²Œ ì²¨ì‚­**í•´ì£¼ì„¸ìš”.

### 1) ì§€ì›ìì˜ ê¸°ë³¸ ì •ë³´
{profile_info}

### 2) í•™ë ¥
{educations}

### 3) ê²½ë ¥
{careers}

### 4) ìê²©ì¦
{certs}

### 5) ìŠ¤í‚¬
{skills}

### 6) ì‚¬ìš© ì–¸ì–´
{langs}

### 7) ìê¸°ì†Œê°œì„œ ì œëª©
{req.essayTitle}

### 8) ìê¸°ì†Œê°œì„œ ë³¸ë¬¸
{req.essayContent}

---

### ğŸ” ì²¨ì‚­ ê·œì¹™
1) ì§€ì›ìì˜ ì´ë ¥ê³¼ ë§ì§€ ì•ŠëŠ” ë‚´ìš©ì´ ìˆìœ¼ë©´ ì •í™•íˆ ì§€ì   
2) ê²½ë ¥Â·ìŠ¤í‚¬ê³¼ ì—°ê²°ë˜ëŠ” í‘œí˜„ ì œì•ˆ  
3) ì§€ì› ì§ë¬´ì— ì–´ìš¸ë¦¬ì§€ ì•ŠëŠ” ë¬¸ì¥ì€ ìì—°ìŠ¤ëŸ½ê²Œ ê°œì„   
4) ë¶€ì¡±í•œ ë¬¸ë§¥Â·ì„±ê³¼Â·ê°•ì  ë³´ì™„ ì¶”ì²œ  
5) ë§ˆì§€ë§‰ì—ëŠ” "ê°œì„ ëœ ìê¸°ì†Œê°œì„œ"ë¥¼ ì™„ì „í•œ ë¬¸ì¥ìœ¼ë¡œ ì¬ì‘ì„±

---

ì´ì œ ì²¨ì‚­ì„ ì‹œì‘í•´ì¤˜.
        """

        # ğŸ”¥ OpenAI í˜¸ì¶œ
        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ ì±„ìš©ë‹´ë‹¹ìì…ë‹ˆë‹¤."},
                {"role": "users", "content": prompt}
            ],
            max_tokens=1500,
            temperature=0.3
        )

        feedback = completion.choices[0].message.content

        print("ğŸ“¤ AI ì²¨ì‚­ ê²°ê³¼ ë°˜í™˜")
        return {"feedback": feedback}

    except Exception as e:
        print("âŒ ì²¨ì‚­ ì˜¤ë¥˜:", e)
        return {"feedback": f"AI ì²¨ì‚­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}

class MatchRequest(BaseModel):
    user: Dict[str, Any]
    resume: Dict[str, Any]
    company: Dict[str, Any]
    job: Dict[str, Any]


# ai ë§¤ì¹­ ì‹œìŠ¤í…œ
class MatchBatchRequest(BaseModel):
    user: Dict[str, Any]
    resume: Dict[str, Any]
    jobs: List[Dict[str, Any]]  # [{jobId, job, company}]


@app.post("/ai/match-batch")
async def match_batch(req: MatchBatchRequest):
    try:
        # âœ… 1) ID 1001~1021ë§Œ í•„í„°ë§
        filtered_jobs = [job for job in req.jobs if 1001 <= job.get("id", 0) <= 1021]

        if not filtered_jobs:
            print("âš ï¸ ì¡°ê±´ì— ë§ëŠ” JobPostsê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {"results": []}

        # âœ… 2) ê° ê³µê³ ë³„ë¡œ ê°„ì†Œí™”ëœ í…ìŠ¤íŠ¸ ìƒì„± (í† í° ì ˆê°ìš©)
        def summarize_job(job):
            job_text = f"""
            ğŸ“Œ ì œëª©: {job.get('title')}
            ğŸ“ ìœ„ì¹˜: {job.get('location')}
            ğŸ’¼ ê²½ë ¥: {job.get('careerLevel')}
            ğŸ“ í•™ë ¥: {job.get('education')}
            ğŸ’° ê¸‰ì—¬: {job.get('salary')}
            ğŸ“‹ ë‚´ìš© ìš”ì•½: {(job.get('content') or '')[:800]}
            """
            return job_text.strip()

        summarized_jobs = [summarize_job(job) for job in filtered_jobs]

        # âœ… 3) GPTì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
ë‹¹ì‹ ì€ ì „ë¬¸ ì±„ìš©ë‹´ë‹¹ìì…ë‹ˆë‹¤.
ì‚¬ìš©ì ì •ë³´ì™€ ì´ë ¥ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì•„ë˜ ì±„ìš©ê³µê³ (ID 1001~1021 ì¤‘ í•´ë‹¹ ê³µê³ ë“¤)ì— ëŒ€í•´
ê°ê° **ì í•©ë„ ì ìˆ˜(0~100)** ì™€ **ë“±ê¸‰(A+~D)** ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ê³„ì‚°í•˜ì„¸ìš”.

### ğŸ‘¤ ì‚¬ìš©ì ì •ë³´
{json.dumps(req.user, ensure_ascii=False, indent=2)}

### ğŸ“„ ì´ë ¥ì„œ ì •ë³´
{json.dumps(req.resume, ensure_ascii=False, indent=2)}

### ğŸ“¢ ì±„ìš©ê³µê³  ë¦¬ìŠ¤íŠ¸ (ìš”ì•½)
{json.dumps(summarized_jobs, ensure_ascii=False, indent=2)}

ì¶œë ¥ í˜•ì‹(JSON ONLY):
{{
  "results": [
    {{
      "jobId": 1001,
      "score": 87,
      "grade": "A",
      "reasons": ["ì´ìœ 1", "ì´ìœ 2"]
    }}
  ]
}}
"""

        # âœ… 4) GPT í˜¸ì¶œ (ìš”ì•½ëœ ì…ë ¥ìœ¼ë¡œ í† í° ì´ˆê³¼ ë°©ì§€)
        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            response_format={"type": "json_object"},
            messages=[{"role": "user", "content": prompt}],
            max_tokens=1500,
            temperature=0.2
        )

        output = completion.choices[0].message.content
        result = json.loads(output)

        # âœ… 5) ê²°ê³¼ ê²€ì¦ ë° í›„ì²˜ë¦¬
        if "results" not in result:
            print("âš ï¸ GPT ì‘ë‹µ í¬ë§· ì´ìƒ, ê¸°ë³¸ ì ìˆ˜ ìƒì„±")
            result["results"] = []

        # GPT ì‘ë‹µì— gradeê°€ ì—†ê±°ë‚˜ ì ìˆ˜ê°€ ì´ìƒí•œ ê²½ìš° ë°©ì–´ ë¡œì§
        final_results = []
        for job_result in result["results"]:
            score = int(job_result.get("score", 0))
            if score > 100:
                score = 100
            elif score < 0:
                score = 0

            # ë“±ê¸‰ ìë™ ê³„ì‚° (A+~D)
            if score >= 95:
                grade = "A+"
            elif score >= 85:
                grade = "A"
            elif score >= 75:
                grade = "B"
            elif score >= 65:
                grade = "C"
            else:
                grade = "D"

            job_result["grade"] = job_result.get("grade", grade)
            final_results.append(job_result)

        # âœ… 6) ì ìˆ˜ìˆœ ì •ë ¬ + ìƒìœ„ 10ê°œë§Œ ë°˜í™˜
        final_results.sort(key=lambda x: x.get("score", 0), reverse=True)
        top10 = final_results[:10]

        print(f"âœ… ë§¤ì¹­ ì™„ë£Œ (í•„í„°ë§ëœ {len(filtered_jobs)}ê±´ ì¤‘ ìƒìœ„ 10ê°œ ë°˜í™˜)")
        return {"results": top10}

    except Exception as e:
        print("âŒ Batch Matching Error:", e)
        return {"results": []}


if __name__ == "__main__":
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)